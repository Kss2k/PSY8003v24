ggplot(plot_df, aes(x, y)) +
geom_point() +
geom_line()
initial_odds <- 0.00001/10
y = c(initial_odds)
for (i in 2:100){
y[i] <- y[i-1]*3.276
}
plot_df <- data.frame(x = seq(1,100, 1),
y = y/(y+1))
ggplot(plot_df, aes(x, y)) +
geom_point() +
geom_line()
exp(coefficents_model[ "(Intercept)"])
initial_odds <- exp(coefficents_model[ "(Intercept)"])
y = c(initial_odds)
for (i in 2:100){
y[i] <- y[i-1]*3.276
}
plot_df <- data.frame(x = seq(1,100, 1),
y = y/(y+1))
ggplot(plot_df, aes(x, y)) +
geom_point() +
geom_line()
initial_odds <- exp(coefficents_model[ "(Intercept)"])
y = c(initial_odds)
for (i in 2:40){
y[i] <- y[i-1]*3.276
}
plot_df <- data.frame(x = seq(1,40, 1),
y = y/(y+1))
ggplot(plot_df, aes(x, y)) +
geom_point() +
geom_line()
initial_odds <- exp(coefficents_model[ "(Intercept)"])
y = c(initial_odds)
for (i in 2:40){
y[i] <- y[i-1]*exp(coefficents_model["Age2"])
plot_df <- data.frame(x = seq(1,40, 1),
y = y/(y+1))
ggplot(plot_df, aes(x, y)) +
geom_point() +
geom_line()
initial_odds <- exp(coefficents_model[ "(Intercept)"])
y = c(initial_odds)
for (i in 2:40){
y[i] <- y[i-1]*exp(coefficents_model["Age2"])
}
plot_df <- data.frame(x = seq(1,40, 1),
y = y/(y+1))
ggplot(plot_df, aes(x, y)) +
geom_point() +
geom_line()
initial_odds <- exp(coefficents_model[ "(Intercept)"] + coefficents_model["Age2"])
y = c(initial_odds)
for (i in 2:40){
y[i] <- y[i-1]*exp(coefficents_model["Age2"])
}
plot_df <- data.frame(x = seq(1,40, 1),
y = y/(y+1))
ggplot(plot_df, aes(x, y)) +
geom_point() +
geom_line()
initial_odds <- exp(coefficents_model[ "(Intercept)"] + coefficents_model["Age2"])
y = c(initial_odds)
for (i in 2:40){
y[i] <- y[i-1]*exp(coefficents_model["Age2"])
}
plot_df <- data.frame(x = seq(1,40, 1),
y = y
ggplot(plot_df, aes(x, y)) +
initial_odds <- exp(coefficents_model[ "(Intercept)"] + coefficents_model["Age2"])
y = c(initial_odds)
for (i in 2:40){
y[i] <- y[i-1]*exp(coefficents_model["Age2"])
}
plot_df <- data.frame(x = seq(1,40, 1),
y = y)
ggplot(plot_df, aes(x, y)) +
geom_point() +
geom_line()
# Gathering the dataset used in our model (this way we do not need to remove missing values our selves)
model_data_with_predictions <- reg_survived_age[["model"]] |>
mutate(predicted_logit = predict(reg_survived_age))
# Converting fitted logit to probabilites
model_data_with_predictions <- model_data_with_predictions %>% mutate(
predicted = 1/(1 + exp(-predicted_logit))
)
# Using the case_when function to predict which category someone belongs to
model_data_with_predictions <- model_data_with_predictions %>% mutate(
predicted = case_when(predicted <= 0.5 ~ 0,
predicted >= 0.5 ~ 1)
)
# Optionally we can just use the logit it selv, since 0.5 corresponds to 0 logit
model_data_with_predictions <- model_data_with_predictions %>% mutate(
predicted2 = case_when(predicted_logit <= 0 ~ 0,
predicted_logit >= 0 ~ 1)
)
# Using probability
table(model_data_with_predictions$Survived,
model_data_with_predictions$predicted)
# Using logit
table(model_data_with_predictions[,1],
model_data_with_predictions[,4])
psummary(reg_survived_age, a = T)
psummary(reg_survived_age, accuracy = T)
values_to_predict <- data.frame(Age2 = c(seq(0,
40,
1)
)
)
values_to_predict = mutate(values_to_predict, predicted = predict(reg_survived_age, newdata =values_to_predict) |> plogis() |> round(5))
values_to_predict %>% ggplot(aes(x = Age2,
y = predicted)) +
geom_point() +
geom_smooth(method = "glm", method.args = list(family = binomial), se = F )
visreg(reg_survived_age, Age2)
library(tidyverse)
library(Statamarkdown)
library(pprint)
# New Packages
# new_packages <- c("DescTools", "visreg", "lmtest")
# install.packages(new_packages)
library(visreg)
library(lmtest)
library(DescTools)
setwd("C:/Users/slupp/OneDrive/Skrivebord/NTNU/Mehmet/PSY8003/Logistic_regression")
titanic <- readRDS("titanic.rds")
reg_survived_age <- glm(Survived ~ Age2,
family = binomial(link = "logit"),
data = titanic)
summary(reg_survived_age)
# library(lmtest)
lrtest(reg_survived_age)
# library(DescTools)
PseudoR2(reg_survived_age, which = "McFadden" # Sane as in STATA and pprint
)
psummary(reg_survived_age)
cat(interpretation_1)
coefficents_model <- coefficients(reg_survived_age)
coefficents_model
plogis(coefficents_model) |> format(scientific = F)
prob_10 <- plogis(coefficents_model[ "(Intercept)"] + 10*coefficents_model["Age2"])
prob_20 <- plogis(coefficents_model[ "(Intercept)"] + 20*coefficents_model["Age2"])
prob_10 |> round(3)
prob_20 |> round(3)
(prob_20 - prob_10) |> round(3)
prob_20 <- plogis(coefficents_model[ "(Intercept)"] + 20*coefficents_model["Age2"])
prob_30 <- plogis(coefficents_model[ "(Intercept)"] + 30*coefficents_model["Age2"])
prob_20 |> round(3)
prob_30 |> round(3)
(prob_30 - prob_20) |> round(3)
values_to_predict <- data.frame(Age2 = c(seq(0,
40,
5)
)
)
predict(reg_survived_age, newdata =values_to_predict) |> plogis() |> round(5)
values_to_predict <- data.frame(Age2 = c(seq(0,
40,
1)
)
)
values_to_predict = mutate(values_to_predict, predicted = predict(reg_survived_age, newdata =values_to_predict) |> plogis() |> round(5))
values_to_predict %>% ggplot(aes(x = Age2,
y = predicted)) +
geom_point() +
geom_smooth(method = "glm", method.args = list(family = binomial), se = F )
visreg(reg_survived_age, Age2)
visreg(reg_survived_age, Age2, data = titanic)
visreg(reg_survived_age, Age2, data = titanic)
visreg(reg_survived_age, Age2, data = titanic)
visreg(reg_survived_age)
# Y = logit
visreg(reg_survived_age)
# Y = Survived/probability
visreg(reg_survived_age, type = "response")
# Y = Survived/probability
visreg(reg_survived_age, scale = "response")
values_to_predict <- data.frame(Age2 = c(seq(0,
40,
1)
)
)
values_to_predict = mutate(values_to_predict, predicted = predict(reg_survived_age, newdata =values_to_predict) |> plogis() |> round(5))
values_to_predict %>% ggplot(aes(x = Age2,
y = predicted)) +
geom_point() +
geom_smooth(method = "glm", method.args = list(family = binomial), se = F )
View(titanic)
reg_survived_gender_age <- glm(Survived ~ Sex + Age, data = titanic)
reg_survived_gender_age <- glm(Survived ~ Sex + Age,
data = titanic,
family = binomial(link = "logit") )
psummary(reg_survived_age)
reg_survived_gender_age <- glm(Survived ~ Sex + Age,
data = titanic,
family = binomial(link = "logit") )
psummary(reg_survived_age)
reg_survived_sex_age <- glm(Survived ~ Sex + Age,
data = titanic,
family = binomial(link = "logit") )
psummary(reg_survived_sex_age, accuracy = T)
interpretation_1 <- "1. Firstly we can see that the model as a whole is significant and has a large Pseudo R2 \n
2. Secondly we can see that the intercept is -24, indicating an estimated log(odds) (logit) of -24 at age = 0. \n
3. Thirdly we can see that the coefficient for age2 is 1.18 (p <.001) indicating a 1.18 increas in logit (increasing odds for surviving) per one unit change (1 year) in age. \n"
interpretation_2 <- "1. Firstly we can see that the model as a whole is significant and has a large Pseudo R2 \n
2. Secondly we can see that the intercept is 1.277-, indicating an estimated log(odds) (logit) of 1.277 at age = 0 and sex = female. \n
3. Thirdly we can see that the coefficient for age is -0.0054 (p = .390) which is not significant, if it were it would indicate a 0.0054 decrease in logit (decreasing odds for surviving) per one unit change (1 year) in age, controlled for sex. \n
4. We can se that Sex has a coefficient of -2.47 (p < .001) indicating that men have 2.47 lower log(odds) of surviving. \n
5. We can see that the model has an okay sensitivity at 67%, and a better specificity at 84.91%, but this is likely because more people died, than survived"
cat(interpretation_2)
mean_age <- mean(titanic$Age)
coefficents_model <- coefficients(reg_survived_sex_age)
mean_age <- mean(titanic$Age, na.rm = T
)
prob_mean_age_female <- plogis(coefficents_model["(Intercept)"] +
mean_age*coefficents_model["Age"])
prob_mean_age_male <- plogis(coefficents_model["(Intercept)"] +
mean_age*coefficents_model["Age"] +
coefficents_model["Sex"])
prob_mean_age_female
prob_mean_age_male
prob_mean_age_male - prob_mean_age_female
coefficents_model <- coefficients(reg_survived_sex_age)
mean_age <- mean(titanic$Age, na.rm = T
)
prob_mean_age_female <- plogis(coefficents_model["(Intercept)"] +
mean_age*coefficents_model["Age"])
prob_mean_age_male <- plogis(coefficents_model["(Intercept)"] +
mean_age*coefficents_model["Age"] +
coefficents_model["Sexmale"])
prob_mean_age_female
prob_mean_age_male
prob_mean_age_male - prob_mean_age_female
visreg(reg_survived_sex_age, scale = "response")
visreg(reg_survived_sex_age, scale = "response", type = "conditional")
visreg(reg_survived_sex_age, xvar = "Age", by = "Sex", scale = "response")
reg_survived_sex_int_age <- glm(Survived ~ Sex*Age, data = titanic)
psummary(reg_survived_sex_int_age, accuracy = T)
reg_survived_sex_int_age <- glm(Survived ~ Sex*Age,
data = titanic,
family = binomial(link = "logit"))
psummary(reg_survived_sex_int_age, accuracy = T)
visreg(reg_survived_sex_int_age, xvar = "Age", by = "Sex", scale = "response")
titanic %>%  ggplot(aes(x = Age,
y = Survived,
colour = Sex)) +
geom_point() +
geom_smooth(method = "glm", method.args = family("binomial"))
titanic %>%  ggplot(aes(x = Age,
y = Survived,
colour = Sex)) +
geom_point() +
geom_smooth(method = "glm", method.args = list(family = binomial))
titanic %>%  ggplot(aes(x = Age,
y = Survived,
colour = Sex)) +
geom_point() +
geom_smooth(method = "glm",
method.args = list(family = binomial),
fullrang = T)
titanic %>%  ggplot(aes(x = Age,
y = Survived,
colour = Sex)) +
geom_point() +
geom_smooth(method = "glm",
method.args = list(family = binomial),
fullrange = T)
reg_int_sex_age_pclass <- glm(Survived ~ Sex + Age + Pclass,
data = titanic,
family = binomial(link = "logit"))
psummary(reg_int_sex_age_pclass)
reg_int_sex_age_pclass <- glm(Survived ~ Sex*Age*Pclass,
data = titanic,
family = binomial(link = "logit"))
psummary(reg_int_sex_age_pclass)
is.ordered(titanic$Pclass)
reg_int_sex_age_pclass <- glm(Survived ~ Age*Pclass,
data = titanic,
family = binomial(link = "logit"))
psummary(reg_int_sex_age_pclass)
str(titanic$Pclass)
Titanic
titanic$Pclass |> as.factor()
reg_int_sex_age_pclass <- glm(Survived ~ Sex*Age*Pclass,
data = titanic,
family = binomial(link = "logit"))
psummary(reg_int_sex_age_pclass)
library(margins)
library(margins)
library(margins)
predictions <- margins(reg_int_sex_age_pclass, at = list(Sex = c(0,1),
Pclass = c(1,2,3),
Age = seq(0,50,10)))
library(margins)
predictions <- margins(reg_int_sex_age_pclass, at = list(Sex = c("male",
"female"),
Pclass = c(1,2,3),
Age = seq(0,50,10)))
library(margins)
predictions <- margins(reg_int_sex_age_pclass, at = list(Sex = c("male",
"female"),
Pclass = c(1,2,3),
Age = seq(0,50,10)))
View(predictions)
library(margins)
predictions <- margins(reg_int_sex_age_pclass, at = list(Sex = c("male",
"female"),
Pclass = c(1,2,3),
Age = seq(0,50,10)
)
)
predictions <- predictions %>% mutate(Pclass = as.factor(Pclass))
predictions %>% ggplot(aes(x = "Age"))
library(margins)
predictions <- margins(reg_int_sex_age_pclass, at = list(Sex = c("male",
"female"),
Pclass = c(1,2,3),
Age = seq(0,50,10)
)
)
predictions <- predictions %>% mutate(Pclass = as.factor(Pclass))
predictions %>% ggplot(aes(x = "Age",
y = "fitted",
colour = Sex,
linetype = Pclass)) +
geom_smooth(method = "glm", method.args = list(family = binomial))
library(margins)
predictions <- margins(reg_int_sex_age_pclass, at = list(Sex = c("male",
"female"),
Pclass = c(1,2,3),
Age = seq(0,50,10)
)
)
predictions <- predictions %>% mutate(Pclass = as.factor(Pclass))
predictions %>% ggplot(aes(x = "Age",
y = "fitted",
colour = Sex,
linetype = Pclass)) +
geom_point() +
geom_smooth(method = "glm", method.args = list(family = binomial))
library(margins)
predictions <- margins(reg_int_sex_age_pclass, at = list(Sex = c("male",
"female"),
Pclass = c(1,2,3),
Age = seq(0,50,10)
)
)
predictions <- predictions %>% mutate(Pclass = as.factor(Pclass))
predictions %>% ggplot(aes(x = Age,
y = fitted,
colour = Sex,
linetype = Pclass)) +
geom_point() +
geom_smooth(method = "glm", method.args = list(family = binomial))
library(margins)
predictions <- margins(reg_int_sex_age_pclass, at = list(Sex = c("male",
"female"),
Pclass = c(1,2,3),
Age = seq(0,50,10)
)
)
predictions <- predictions %>% mutate(Pclass = as.factor(Pclass))
predictions %>% ggplot(aes(x = Age,
y = fitted,
colour = c(Sex, Pclass),
#linetype = Pclass
)) +
geom_point() +
geom_smooth(method = "glm", method.args = list(family = binomial))
library(margins)
predictions <- margins(reg_int_sex_age_pclass, at = list(Sex = c("male",
"female"),
Pclass = c(1,2,3),
Age = seq(0,50,10)
)
)
predictions <- predictions %>% mutate(Pclass = as.factor(Pclass))
predictions %>% ggplot(aes(x = Age,
y = fitted,
colour = Sex,
linetype = Pclass)
) +
geom_point() +
geom_smooth(method = "glm", method.args = list(family = binomial))
predictions <- margins(reg_int_sex_age_pclass, at = list(Sex = c("male",
"female"),
Pclass = c(1,2,3),
Age = seq(0,50,10)
)
)
predictions <- predictions %>% mutate(Pclass = as.factor(Pclass))
predictions %>% ggplot(aes(x = Age,
y = fitted,
colour = Sex)
) +
geom_point() +
geom_smooth(method = "glm", method.args = list(family = binomial)) +
facet_wrap(~ Pclass)
coefficents_model <- coefficients(reg_survived_age)
coefficents_model
plogis(coefficents_model) |> format(scientific = F)
exp(coefficents_model)
initial_odds <- exp(coefficents_model[ "(Intercept)"] + coefficents_model["Age2"])
y = c(initial_odds)
for (i in 2:40){
y[i] <- y[i-1]*exp(coefficents_model["Age2"])
}
plot_df <- data.frame(x = seq(1,40, 0.1),
y = y)
initial_odds <- exp(coefficents_model[ "(Intercept)"] + coefficents_model["Age2"])
y = c(initial_odds)
for (i in 2:40){
y[i] <- y[i-1]*exp(coefficents_model["Age2"])
}
plot_df <- data.frame(x = seq(1,40, 1),
y = y)
ggplot(plot_df, aes(x, y)) +
geom_line()
initial_odds <- exp(coefficents_model[ "(Intercept)"] + coefficents_model["Age2"])
y = c(initial_odds)
for (i in 2:40){
y[i] <- y[i-1]*exp(coefficents_model["Age2"])
}
plot_df <- data.frame(x = seq(1,40, 1),
y = y)
ggplot(plot_df, aes(x, y)) +
geom_point() +
geom_line()
library(pprint)
devtools::install_github("kss2k/pprint")
library(pprint)
library(tidyverse)
library(Statamarkdown)
setwd("C:/Users/slupp/OneDrive/Skrivebord/NTNU/Mehmet/PSY8003/multilevel")
setwd("~/Dropbox/PSY8003_v24/Lab-sessions/multilevel/")
depression <- readRDS("depression.rds")
depression.long <- depression %>%
pivot_longer(cols = starts_with("week") | starts_with("BDI"),
names_to = c(".value", "session"),
names_pattern = "(BDI|week)([0-9]+)") %>%
mutate(session = as.integer(session))
depression.long.BDI <- pivot_longer(depression,
cols = starts_with("BDI"),
names_to = "session",
values_to = "BDI",
names_prefix = "BDI",
names_transform = as.integer
) %>% select(!starts_with("week"))
depression.long.BDI <- depression %>%
pivot_longer(cols = starts_with("BDI"),
names_to = "session",
values_to = "BDI",
names_prefix = "BDI",
names_transform = as.integer) %>%
select(!starts_with("week")) # This excludes week from the dataset
depression.long.week <- depression %>%
pivot_longer(cols = starts_with("week"),
names_to = "session",
values_to = "week",
names_prefix = "week",
names_transform = as.integer) %>%
select(!starts_with("BDI")) # This excludes BDI from the dataset
depression.long2 <- inner_join(depression.long.week,
depression.long.BDI)
depression.wide <- pivot_wider(depression.long,
names_from = session,
values_from = c(week, BDI))
psummary(depression.wide)
diet <- readRDS("diet.rds")
diet.long <- pivot_longer(diet,
cols = c("pre_weight", "post_weight"),
names_to = "time",
values_to = "weight"
)
# Convert To Integer
diet.long <- diet.long %>% mutate(time = case_when(time == "pre_weight" ~ 0,
time == "post_weight" ~ 1)
)
# Also we must estimate slope and intercept seperately, if not we will compute a third variance which is the covariance between slope and intercept giving us more than 152 variances
reg1 <- lmer(weight ~ time + (1 | person) + (0 + time| person),
data = diet.long)
library(pprint)
library(tidyverse)
library(Statamarkdown)
library(lmerTest)
diet <- readRDS("diet.rds")
diet.long <- pivot_longer(diet,
cols = c("pre_weight", "post_weight"),
names_to = "time",
values_to = "weight"
)
# Convert To Integer
diet.long <- diet.long %>% mutate(time = case_when(time == "pre_weight" ~ 0,
time == "post_weight" ~ 1)
)
# Also we must estimate slope and intercept seperately, if not we will compute a third variance which is the covariance between slope and intercept giving us more than 152 variances
reg1 <- lmer(weight ~ time + (1 | person) + (0 + time| person),
data = diet.long)
reg2 <- lmer(weight ~ time + (1 + time|person),
data = diet.long)
# Also we must estimate slope and intercept seperately, if not we will compute a third variance which is the covariance between slope and intercept giving us more than 152 variances
reg1 <- lmer(weight ~ time + (1 | person) + (0 + time| person),
data = diet.long)
# install.packages("lme4")
# install.packages("lmerTest")
library(lmerTest)
empty_mod <- lmer(BDI ~ (1|ID), data = depression.long, REML = TRUE)
empty_mod <- lmer(BDI ~ (1|ID), data = depression.long, REML = TRUE # Default
)
summary(empty_mod)
